{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766c9899-99a0-4a3b-acb9-20fa20dfa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요 라이브러리 임포트\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import math  # math 모듈 임포트 추가\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c40d3ed-6a1c-4ff8-90b5-b9819da8333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 리사이징 함수\n",
    "def resize_image(image_path, target_size):\n",
    "    \"\"\"\n",
    "    이미지를 지정한 크기로 리사이즈합니다.\n",
    "    :param image_path: 원본 이미지 경로\n",
    "    :param target_size: 리사이즈할 크기 (width, height)\n",
    "    :return: 리사이즈된 이미지\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None\n",
    "    resized_image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "    return resized_image\n",
    "\n",
    "# 디렉토리 내 모든 이미지를 리사이즈하여 저장\n",
    "def makedir_resize(input_folder, output_folder, target_size):\n",
    "    \"\"\"\n",
    "    폴더 내 이미지를 리사이즈하여 저장하는 함수\n",
    "    :param input_folder: 원본 이미지가 저장된 폴더\n",
    "    :param output_folder: 리사이즈된 이미지를 저장할 폴더\n",
    "    :param target_size: 리사이즈할 크기 (width, height)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for image_name in os.listdir(input_folder):\n",
    "        image_path = os.path.join(input_folder, image_name)\n",
    "        if not image_name.lower().endswith((\".jpg\", \".png\")):\n",
    "            print(f\"Skipped non-image file: {image_name}\")\n",
    "            continue\n",
    "\n",
    "        resized_image = resize_image(image_path, target_size)\n",
    "        if resized_image is not None:\n",
    "            output_image_path = os.path.join(output_folder, image_name)\n",
    "            cv2.imwrite(output_image_path, resized_image)\n",
    "            print(f\"Resized image saved to: {output_image_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "969f91b8-746b-472a-a563-fc64b0d3513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 회전 함수\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    이미지를 특정 각도로 회전시킵니다.\n",
    "    :param image: 원본 이미지\n",
    "    :param angle: 회전할 각도\n",
    "    :return: 회전된 이미지\n",
    "    \"\"\"\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    # 이미지의 새로운 경계 계산\n",
    "    cos = np.abs(rotation_matrix[0, 0])\n",
    "    sin = np.abs(rotation_matrix[0, 1])\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "\n",
    "    # 회전 행렬에 새로운 크기 적용 (중심 이동)\n",
    "    rotation_matrix[0, 2] += (new_w / 2) - center[0]\n",
    "    rotation_matrix[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "    # 회전 및 Zero Padding 적용\n",
    "    rotated_image = cv2.warpAffine(\n",
    "        image, \n",
    "        rotation_matrix, \n",
    "        (new_w, new_h), \n",
    "        borderValue=(0, 0, 0)  # Zero Padding\n",
    "    )\n",
    "    return rotated_image\n",
    "\n",
    "# 데이터 증강 함수 (회전)\n",
    "def makedir_rotate(input_folder, output_folder, n):\n",
    "    \"\"\"\n",
    "    데이터셋을 n배로 증강. 각 이미지를 (360/n * k)도로 회전 (k=1, ... ,n-1)\n",
    "    :param input_folder: 원본 이미지가 저장된 폴더\n",
    "    :param output_folder: 회전된 이미지를 저장할 폴더\n",
    "    :param n: 회전 각도 분할 수\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    angles = [(360 / n) * i for i in range(1, n)]\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if not filename.lower().endswith((\".jpg\", \".png\")):\n",
    "            print(f\"Skipped non-image file: {filename}\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        for angle in angles:\n",
    "            rotated_image = rotate_image(image, angle)\n",
    "            \n",
    "            # 새로운 파일명 생성\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            rotated_filename = f\"{name}_rotated_{int(angle)}{ext}\"\n",
    "            \n",
    "            # 회전된 이미지 저장\n",
    "            cv2.imwrite(os.path.join(output_folder, rotated_filename), rotated_image)\n",
    "            print(f\"Saved rotated image: {rotated_filename}\")\n",
    "        \n",
    "        # 원본 이미지도 저장\n",
    "        cv2.imwrite(os.path.join(output_folder, filename), image)\n",
    "        print(f\"Original image saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c9f31e-9f85-4f92-9dec-69cbba204cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_zeropadding(image, size, position):\n",
    "    \"\"\"\n",
    "    이미지를 4개의 모서리를 기준으로 지정된 크기로 자릅니다. \n",
    "    잘라낸 영역이 이미지 범위를 벗어날 경우 제로 패딩을 적용합니다.\n",
    "    \n",
    "    :param image: 원본 이미지 (numpy 배열)\n",
    "    :param size: 자를 윈도우의 크기 (width, height) 튜플\n",
    "    :param position: 자를 위치, 'top-left', 'top-right', 'bottom-left', 'bottom-right' 중 하나\n",
    "    :return: 잘라낸 이미지 (지정된 크기와 동일한 numpy 배열)\n",
    "    \"\"\"\n",
    "    window_w, window_h = size\n",
    "    img_h, img_w = image.shape[:2]\n",
    "\n",
    "    # 위치에 따른 시작 좌표 계산\n",
    "    if position == 'top-left':\n",
    "        x_start, y_start = 0, 0\n",
    "    elif position == 'top-right':\n",
    "        x_start, y_start = img_w - window_w, 0\n",
    "    elif position == 'bottom-left':\n",
    "        x_start, y_start = 0, img_h - window_h\n",
    "    elif position == 'bottom-right':\n",
    "        x_start, y_start = img_w - window_w, img_h - window_h\n",
    "    else:\n",
    "        raise ValueError(\"position 파라미터는 'top-left', 'top-right', 'bottom-left', 'bottom-right' 중 하나여야 합니다.\")\n",
    "\n",
    "    # 잘라낼 영역의 끝 좌표\n",
    "    x_end = x_start + window_w\n",
    "    y_end = y_start + window_h\n",
    "\n",
    "    # 제로 패딩을 위한 빈 이미지 생성 (검은색)\n",
    "    cropped = np.zeros((window_h, window_w, image.shape[2]), dtype=image.dtype)\n",
    "\n",
    "    # 원본 이미지 내에서 자를 수 있는 영역 계산\n",
    "    x1 = max(x_start, 0)\n",
    "    y1 = max(y_start, 0)\n",
    "    x2 = min(x_end, img_w)\n",
    "    y2 = min(y_end, img_h)\n",
    "\n",
    "    # 잘라낸 이미지를 배치할 위치 계산\n",
    "    pad_x = max(-x_start, 0)\n",
    "    pad_y = max(-y_start, 0)\n",
    "\n",
    "    # 원본 이미지에서 잘라낸 부분을 새로운 이미지에 복사\n",
    "    cropped[pad_y:pad_y + (y2 - y1), pad_x:pad_x + (x2 - x1)] = image[y1:y2, x1:x2]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "def makedir_crop(input_folder, output_folder, crop_size=(200, 200)):\n",
    "    \"\"\"\n",
    "    입력 폴더 내의 모든 이미지를 네 모서리에서 지정된 크기로 자르고, \n",
    "    잘라낸 이미지를 출력 폴더에 저장합니다.\n",
    "    \n",
    "    :param input_folder: 원본 이미지가 저장된 폴더\n",
    "    :param output_folder: 잘라낸 이미지를 저장할 폴더\n",
    "    :param crop_size: 잘라낼 윈도우의 크기 (width, height) 튜플. 기본값은 (200, 200)\n",
    "    \"\"\"\n",
    "    # 출력 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"출력 폴더 생성: {output_folder}\")\n",
    "\n",
    "    # 잘라낼 위치 목록\n",
    "    positions = ['top-left', 'top-right', 'bottom-left', 'bottom-right']\n",
    "\n",
    "    # 입력 폴더 내의 모든 파일 처리\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
    "            print(f\"이미지가 아닌 파일을 건너뜁니다: {filename}\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"이미지를 불러오는 데 실패했습니다: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        for position in positions:\n",
    "            cropped_image = crop_zeropadding(image, crop_size, position)\n",
    "\n",
    "            # 파일명 생성: 원본명 + 위치명 + 확장자\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            cropped_filename = f\"{name}_{position}{ext}\"\n",
    "\n",
    "            # 잘라낸 이미지 저장\n",
    "            save_path = os.path.join(output_folder, cropped_filename)\n",
    "            cv2.imwrite(save_path, cropped_image)\n",
    "            print(f\"저장된 잘라낸 이미지: {cropped_filename}\")\n",
    "\n",
    "    print(\"모든 이미지에 대한 크롭 작업이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bbf481a-fc24-4ae7-9370-55a7c2ba2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def add_noise(input_folder, output_folder, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    원본 이미지에 가우지안 노이즈를 추가합니다.\n",
    "    \n",
    "    :param input_folder: 원본 이미지가 저장된 입력 폴더 경로 (문자열)\n",
    "    :param output_folder: 노이즈가 추가된 이미지가 저장될 출력 폴더 경로 (문자열)\n",
    "    :param noise_factor: 노이즈의 강도 (기본값: 0.1)\n",
    "    \"\"\"\n",
    "    # 입력 폴더 존재 여부 확인\n",
    "    if not os.path.exists(input_folder):\n",
    "        raise FileNotFoundError(f\"Input folder '{input_folder}' does not exist.\")\n",
    "    \n",
    "    # 출력 폴더가 없으면 생성\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"Created output folder '{output_folder}'.\")\n",
    "    \n",
    "    # 입력 폴더 내 모든 파일 순회\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        # 현재 폴더의 상대 경로 계산\n",
    "        rel_path = os.path.relpath(root, input_folder)\n",
    "        # 출력 폴더 내 해당 상대 경로에 해당하는 디렉터리 경로 생성\n",
    "        output_dir = os.path.join(output_folder, rel_path)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        for file in files:\n",
    "            # 이미지 파일 확장자 확인\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif')):\n",
    "                input_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # 이미지 열기 및 RGB로 변환\n",
    "                    image = Image.open(input_path).convert('RGB')\n",
    "                    image_np = np.array(image)\n",
    "                    \n",
    "                    # 가우시안 노이즈 생성\n",
    "                    noise = np.random.normal(0, noise_factor * 255, image_np.shape).astype(np.float32)\n",
    "                    noisy_image = image_np + noise\n",
    "                    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "                    \n",
    "                    # 노이즈 이미지 PIL 객체로 변환\n",
    "                    noisy_image_pil = Image.fromarray(noisy_image)\n",
    "                    \n",
    "                    # 증강된 이미지 이름 생성 (예: originalname_noisy.jpg)\n",
    "                    base, ext = os.path.splitext(file)\n",
    "                    noisy_filename = f\"{base}_noisy{ext}\"\n",
    "                    output_path = os.path.join(output_dir, noisy_filename)\n",
    "                    \n",
    "                    # 노이즈 이미지 저장\n",
    "                    noisy_image_pil.save(output_path)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process image '{input_path}': {e}\")\n",
    "    \n",
    "    print(\"Data augmentation with Gaussian noise completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef5619ec-364e-4dc2-a238-4c89116ae782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_history_to_native(history):\n",
    "    \"\"\"\n",
    "    Converts all numpy data types in the history dictionary to native Python types.\n",
    "    \n",
    "    :param history: Dictionary containing training history.\n",
    "    :return: Converted dictionary with native Python types.\n",
    "    \"\"\"\n",
    "    native_history = {}\n",
    "    for key, values in history.items():\n",
    "        native_history[key] = [float(v) for v in values]\n",
    "    return native_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a94c4b8a-b105-49f6-bf21-bdbe7ccc60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_results(results_base_dir, model, history, batch_size, epochs, neurons, dropout):\n",
    "    \"\"\"\n",
    "    하이퍼파라미터 정보를 포함한 디렉토리를 생성하고 그 안에 학습 결과를 저장합니다.\n",
    "    :param results_base_dir: 결과를 저장할 기본 디렉토리\n",
    "    :param model: 학습된 모델\n",
    "    :param history: 모델 학습 히스토리 (history 객체)\n",
    "    :param batch_size: 배치 크기\n",
    "    :param epochs: 에포크 수\n",
    "    :param neurons: 각 레이어의 뉴런 개수 (리스트)\n",
    "    :param dropout: 드롭아웃 비율\n",
    "    \"\"\"\n",
    "    # 하이퍼파라미터 기반 디렉토리 이름 생성\n",
    "    dir_name = f\"bs{batch_size}_ep{epochs}_neurons{'-'.join(map(str, neurons))}_dr{dropout}\"\n",
    "    results_dir = os.path.join(results_base_dir, dir_name)\n",
    "\n",
    "    # 디렉토리 생성\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "    # 모델 저장\n",
    "    model_save_path = os.path.join(results_dir, 'model.h5')\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved at: {model_save_path}\")\n",
    "\n",
    "    # 손실 그래프 저장\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    loss_graph_path = os.path.join(results_dir, 'loss_graph.png')\n",
    "    plt.savefig(loss_graph_path, bbox_inches='tight')\n",
    "    print(f\"Loss graph saved at: {loss_graph_path}\")\n",
    "    plt.close()\n",
    "\n",
    "    # 정확도 그래프 저장\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    accuracy_graph_path = os.path.join(results_dir, 'accuracy_graph.png')\n",
    "    plt.savefig(accuracy_graph_path, bbox_inches='tight')\n",
    "    print(f\"Accuracy graph saved at: {accuracy_graph_path}\")\n",
    "    plt.close()\n",
    "\n",
    "    # 학습 기록 저장 (JSON)\n",
    "    history_path = os.path.join(results_dir, 'training_history.json')\n",
    "    native_history = convert_history_to_native(history.history)\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(native_history, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Training history saved at: {history_path}\")\n",
    "\n",
    "    # 하이퍼파라미터 정보 저장 (JSON)\n",
    "    hyperparams_path = os.path.join(results_dir, 'hyperparameters.json')\n",
    "    hyperparameters = {\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'neurons': neurons,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    with open(hyperparams_path, 'w') as f:\n",
    "        json.dump(hyperparameters, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Hyperparameters saved at: {hyperparams_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75faa03b-218e-4134-a1e5-86a5b9f93005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(IMAGE_SIZE, NEURONS, DROPOUT):\n",
    "    \"\"\"\n",
    "    주어진 뉴런 수와 드롭아웃 비율을 사용하여 모델을 구축합니다.\n",
    "    \n",
    "    :param IMAGE_SIZE: 입력 이미지의 크기 (예: (224, 224))\n",
    "    :param NEURONS: 각 Conv2D 및 Dense 레이어의 뉴런 개수 (리스트)\n",
    "                    예: [32, 64, 128, 256] (마지막 요소는 Dense 레이어)\n",
    "    :param DROPOUT: 드롭아웃 비율 (float)\n",
    "    :return: 컴파일된 Keras 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "        \n",
    "        layers.Conv2D(NEURONS[0], (3, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "\n",
    "        layers.Conv2D(NEURONS[1], (3, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "\n",
    "        layers.Conv2D(NEURONS[2], (3, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(NEURONS[3]),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.Dense(1, activation='sigmoid')  # 이진 분류를 위한 시그모이드 활성화 함수\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def training_model(results_base_dir, build_model_fn, train_dir, IMAGE_SIZE, BATCH_SIZE, EPOCHS, DROPOUT, NEURONS):\n",
    "    \"\"\"\n",
    "    주어진 하이퍼파라미터 조합으로 모델을 학습시키고 결과를 저장합니다.\n",
    "    \n",
    "    :param results_base_dir: 학습 결과를 저장할 기본 디렉터리\n",
    "    :param build_model_fn: 모델을 구축하는 함수\n",
    "    :param train_dir: 훈련 데이터가 저장된 디렉터리 경로\n",
    "    :param IMAGE_SIZE: 입력 이미지의 크기 (예: (224, 224))\n",
    "    :param BATCH_SIZE: 배치 사이즈 리스트\n",
    "    :param EPOCHS: 에포크 수 리스트\n",
    "    :param DROPOUT: 드롭아웃 비율 리스트\n",
    "    :param NEURONS: 각 레이어의 뉴런 개수 리스트 (리스트의 리스트)\n",
    "                    예: [[32, 64, 128, 256], [64, 128, 256, 512]]\n",
    "    \"\"\"\n",
    "    # 모든 하이퍼파라미터 조합 생성\n",
    "    hyperparameter_combinations = list(product(BATCH_SIZE, EPOCHS, DROPOUT, NEURONS))\n",
    "\n",
    "    print(f\"총 {len(hyperparameter_combinations)}개의 하이퍼파라미터 조합을 학습합니다.\")\n",
    "\n",
    "    for idx, (batch_size, epochs, dropout, neurons) in enumerate(hyperparameter_combinations, 1):\n",
    "        print(f\"\\n학습 시작 {idx}/{len(hyperparameter_combinations)}: \"\n",
    "              f\"Batch Size={batch_size}, Epochs={epochs}, Dropout={dropout}, Neurons={neurons}\")\n",
    "\n",
    "        # 데이터 제너레이터 설정\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.1,  # 훈련 데이터의 10%를 검증 데이터로 사용\n",
    "            #최고 성능 모델에서는 0.2였음.\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        seed=42\n",
    "        # 훈련 데이터 제너레이터\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=IMAGE_SIZE,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary',  # 이진 분류를 위한 설정\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            seed = seed\n",
    "        )\n",
    "\n",
    "        # 검증 데이터 제너레이터\n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=IMAGE_SIZE,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary',  # 이진 분류를 위한 설정\n",
    "            subset='validation',\n",
    "            shuffle=False,\n",
    "            seed = seed\n",
    "        )\n",
    "\n",
    "        # 클래스 가중치 계산 (훈련 데이터 기반)\n",
    "        classes = train_generator.classes\n",
    "        class_weights_vals = class_weight.compute_class_weight('balanced', classes=np.unique(classes), y=classes)\n",
    "        class_weights_dict = dict(enumerate(class_weights_vals))\n",
    "\n",
    "        # 모델 구축\n",
    "        model = build_model_fn(IMAGE_SIZE, neurons, dropout)\n",
    "\n",
    "        rlr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',      # 모니터링할 지표\n",
    "            factor=0.2,              # 학습률 감소 비율\n",
    "            patience=5,              # 개선이 없을 때 기다릴 에포크 수\n",
    "            min_lr=1e-7,             # 학습률의 최소값\n",
    "            verbose=1                # 로그 출력\n",
    "        )\n",
    "        \n",
    "        # 모델 학습\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=math.ceil(train_generator.samples / batch_size),\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=math.ceil(validation_generator.samples / batch_size),\n",
    "            verbose=1,  # 학습 과정을 출력\n",
    "            class_weight=class_weights_dict,\n",
    "            callbacks=[rlr]  \n",
    "        )\n",
    "\n",
    "        # 학습 결과 저장\n",
    "        save_training_results(\n",
    "            results_base_dir=results_base_dir,\n",
    "            model=model,\n",
    "            history=history,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            neurons=neurons,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        print(f\"학습 완료 {idx}/{len(hyperparameter_combinations)}\")\n",
    "\n",
    "    print(\"\\n모든 하이퍼파라미터 조합에 대한 학습이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f4d2540-2f4a-4236-b1ff-096fa0d418a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortmodel(models_dir, option=0):\n",
    "    \"\"\"\n",
    "    주어진 디렉터리 내의 모델들을 정확도 또는 손실을 기준으로 정렬합니다.\n",
    "\n",
    "    :param models_dir: 정렬할 모델들이 저장되어 있는 디렉터리 경로 (문자열)\n",
    "    :param option: 정렬 기준 (0=정확도, 1=손실), 기본값은 0\n",
    "    \"\"\"\n",
    "    \n",
    "    # 모델 디렉터리 내의 모든 하위 디렉터리 가져오기\n",
    "    model_dirs = [os.path.join(models_dir, d) for d in os.listdir(models_dir)\n",
    "                  if os.path.isdir(os.path.join(models_dir, d))]\n",
    "\n",
    "    model_performance = []\n",
    "\n",
    "    for model_dir in model_dirs:\n",
    "        # 학습 기록 파일 경로\n",
    "        history_path = os.path.join(model_dir, 'training_history.json')\n",
    "\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'r') as f:\n",
    "                history = json.load(f)\n",
    "            \n",
    "            # 마지막 에포크의 정확도와 손실 가져오기\n",
    "            final_accuracy = history['val_accuracy'][-1]\n",
    "            final_loss = history['val_loss'][-1]\n",
    "\n",
    "            # 모델 정보 저장\n",
    "            model_info = {\n",
    "                'model_dir': model_dir,\n",
    "                'accuracy': final_accuracy,\n",
    "                'loss': final_loss\n",
    "            }\n",
    "            model_performance.append(model_info)\n",
    "        else:\n",
    "            print(f\"Warning: '{history_path}' 파일이 존재하지 않습니다.\")\n",
    "\n",
    "    # 정렬 기준 설정\n",
    "    if option == 0:\n",
    "        # 정확도를 기준으로 내림차순 정렬\n",
    "        sorted_models = sorted(model_performance, key=lambda x: x['accuracy'], reverse=True)\n",
    "    elif option == 1:\n",
    "        # 손실을 기준으로 오름차순 정렬\n",
    "        sorted_models = sorted(model_performance, key=lambda x: x['loss'])\n",
    "    else:\n",
    "        print(\"Invalid option. Please choose 0 for accuracy or 1 for loss.\")\n",
    "        return\n",
    "\n",
    "    # 정렬된 모델 정보 출력\n",
    "    print(f\"{'Rank':<5}{'Model Directory':<50}{'Accuracy':<10}{'Loss':<10}\")\n",
    "    for idx, model in enumerate(sorted_models, 1):\n",
    "        print(f\"{idx:<5}{model['model_dir']:<50}{model['accuracy']:<10.4f}{model['loss']:<10.4f}\")\n",
    "\n",
    "    return sorted_models\n",
    "\n",
    "\n",
    "def show_good_model(sorted_models, n=5):\n",
    "    \"\"\"\n",
    "    상위 n개의 모델 정보를 출력하고, 정확도와 손실을 시각화합니다.\n",
    "    \n",
    "    :param sorted_models: 특정 기준으로 정렬된 모델들 (리스트 of dicts)\n",
    "    :param n: 정보를 몇 번째까지 출력할지 나타내는 정수 (기본값=5)\n",
    "    \"\"\"\n",
    "    # 상위 n개의 모델 선택\n",
    "    top_models = sorted_models[:n]\n",
    "    \n",
    "    if not top_models:\n",
    "        print(\"정렬된 모델 리스트가 비어있습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 상위 n개의 모델 정보 출력\n",
    "    print(f\"{'Rank':<5}{'Model Directory':<60}{'Accuracy':<10}{'Loss':<10}\")\n",
    "    for idx, model_info in enumerate(top_models, 1):\n",
    "        model_dir = model_info['model_dir']\n",
    "        accuracy = model_info['accuracy']\n",
    "        loss = model_info['loss']\n",
    "        print(f\"{idx:<5}{model_dir:<60}{accuracy:<10.4f}{loss:<10.4f}\")\n",
    "    \n",
    "    # 정확도 및 손실 그래프 시각화\n",
    "    accuracies = [model['accuracy'] for model in top_models]\n",
    "    losses = [model['loss'] for model in top_models]\n",
    "    model_names = [os.path.basename(model['model_dir']) for model in top_models]\n",
    "    \n",
    "    # 그래프 크기 설정\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 정확도 막대 그래프\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(model_names, accuracies, color='skyblue')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Top Models Validation Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f\"{acc:.4f}\", ha='center', va='bottom')\n",
    "    \n",
    "    # 손실 막대 그래프\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.bar(model_names, losses, color='salmon')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title('Top Models Validation Loss')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    for bar, loss in zip(bars, losses):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f\"{loss:.4f}\", ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 선택 사항: 각 모델의 구조 요약 출력\n",
    "    print(\"\\n=== 상위 모델들의 구조 요약 ===\")\n",
    "    for idx, model_info in enumerate(top_models, 1):\n",
    "        model_path = os.path.join(model_info['model_dir'], 'model.h5')\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"\\nRank {idx}: {model_info['model_dir']}\")\n",
    "            model = load_model(model_path)\n",
    "            model.summary()\n",
    "        else:\n",
    "            print(f\"\\nRank {idx}: 모델 파일이 존재하지 않습니다: {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6439870c-88dd-43f3-8278-c49ca98ffcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_evaluate(test_dir, model_dir, save_dir, IMAGE_SIZE=(200, 200), BATCH_SIZE=32):\n",
    "    \"\"\"\n",
    "    학습된 모델을 테스트 데이터에 대해 평가하고, 결과를 저장합니다.\n",
    "    \n",
    "    :param test_dir: 테스트 데이터가 있는 디렉터리 경로\n",
    "    :param model_dir: 평가할 모델의 디렉터리 경로 (model.h5 파일이 위치)\n",
    "    :param save_dir: 평가 결과를 저장할 디렉터리 경로\n",
    "    :param IMAGE_SIZE: 입력 이미지의 크기 (기본값=(200, 200))\n",
    "    :param BATCH_SIZE: 배치 사이즈 (기본값=32)\n",
    "    \"\"\"\n",
    "    # 필요한 디렉터리 생성\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"저장 디렉터리 생성: {save_dir}\")\n",
    "    \n",
    "    # 모델 파일 경로\n",
    "    model_path = os.path.join(model_dir, 'model.h5')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Error: 모델 파일이 존재하지 않습니다: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = load_model(model_path)\n",
    "    print(f\"모델 로드 완료: {model_path}\")\n",
    "    \n",
    "    # 테스트 데이터 제너레이터 설정\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',  # 이진 분류인 경우 'binary', 다중 클래스인 경우 'categorical'\n",
    "        shuffle=False  # 평가 시 데이터 순서를 유지\n",
    "    )\n",
    "    \n",
    "    # 클래스 인덱스 확인\n",
    "    print('Class indices:', test_generator.class_indices)\n",
    "    \n",
    "    # 모델 평가\n",
    "    loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "    print(f\"테스트 손실: {loss}\")\n",
    "    print(f\"테스트 정확도: {accuracy}\")\n",
    "    \n",
    "    # 예측 생성\n",
    "    Y_pred = model.predict(test_generator)\n",
    "    y_pred = (Y_pred > 0.5).astype(int).reshape(-1)  # 이진 분류인 경우\n",
    "    \n",
    "    \n",
    "    # 실제 클래스\n",
    "    y_true = test_generator.classes\n",
    "    \n",
    "    # 분류 보고서 생성\n",
    "    report = classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys()))\n",
    "    print(\"분류 보고서:\")\n",
    "    print(report)\n",
    "    \n",
    "    # 분류 보고서를 JSON으로 저장\n",
    "    report_dict = classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys()), output_dict=True)\n",
    "    report_path = os.path.join(save_dir, 'classification_report.json')\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(report_dict, f, indent=4)\n",
    "    print(f\"분류 보고서 JSON 저장: {report_path}\")\n",
    "    \n",
    "    # 혼동 행렬 생성\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"혼동 행렬:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # 혼동 행렬 시각화 및 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    classes = list(test_generator.class_indices.keys())\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # 값 표시\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    cm_path = os.path.join(save_dir, 'confusion_matrix.png')\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    print(f\"혼동 행렬 이미지 저장: {cm_path}\")\n",
    "    \n",
    "    # ROC 곡선 및 AUC 계산 (이진 분류인 경우)\n",
    "    if len(test_generator.class_indices) == 2:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, Y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        roc_path = os.path.join(save_dir, 'roc_curve.png')\n",
    "        plt.savefig(roc_path)\n",
    "        plt.close()\n",
    "        print(f\"ROC 곡선 이미지 저장: {roc_path}\")\n",
    "    \n",
    "    # 결과 요약 저장\n",
    "    summary = {\n",
    "        'test_loss': loss,\n",
    "        'test_accuracy': accuracy,\n",
    "        'classification_report': report_dict,\n",
    "        'confusion_matrix': cm.tolist()  # numpy 배열을 리스트로 변환\n",
    "    }\n",
    "    \n",
    "    if test_generator.num_classes == 1:\n",
    "        summary['roc_auc'] = roc_auc\n",
    "    \n",
    "    summary_path = os.path.join(save_dir, 'evaluation_summary.json')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=4)\n",
    "    print(f\"평가 요약 저장: {summary_path}\")\n",
    "    \n",
    "    # 최고 모델 디렉터리의 그래프 파일 복사\n",
    "    graph_files = ['loss_graph.png', 'accuracy_graph.png']  # 복사할 그래프 파일 목록\n",
    "    for graph_file in graph_files:\n",
    "        source_path = os.path.join(model_dir, graph_file)\n",
    "        if os.path.exists(source_path):\n",
    "            destination_path = os.path.join(save_dir, f\"best_{graph_file}\")\n",
    "            shutil.copy(source_path, destination_path)\n",
    "            print(f\"{graph_file} 복사하여 저장: {destination_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: '{source_path}' 파일이 존재하지 않습니다. 복사하지 않습니다.\")\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"모델 평가가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8fd1781-5fed-4010-b35c-ef639fefe99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_history(model_dir):\n",
    "    \"\"\"\n",
    "    주어진 모델 디렉터리에서 학습 내역을 로드하고, 손실 및 정확도 그래프를 시각화하며,\n",
    "    주요 학습 요약 정보를 출력합니다.\n",
    "    \n",
    "    :param model_dir: 학습 내역을 보고자 하는 모델의 디렉터리 경로 (문자열)\n",
    "    \"\"\"\n",
    "    # 필요한 파일 경로 설정\n",
    "    history_path = os.path.join(model_dir, 'training_history.json')\n",
    "    hyperparams_path = os.path.join(model_dir, 'hyperparameters.json')\n",
    "    \n",
    "    # 학습 내역 파일 존재 여부 확인\n",
    "    if not os.path.exists(history_path):\n",
    "        print(f\"Error: '{history_path}' 파일이 존재하지 않습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 학습 내역 로드\n",
    "    with open(history_path, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # 하이퍼파라미터 로드 (선택 사항)\n",
    "    hyperparameters = {}\n",
    "    if os.path.exists(hyperparams_path):\n",
    "        with open(hyperparams_path, 'r') as f:\n",
    "            hyperparameters = json.load(f)\n",
    "    \n",
    "    # 손실 및 정확도 데이터 추출\n",
    "    loss = history.get('loss')\n",
    "    val_loss = history.get('val_loss')\n",
    "    accuracy = history.get('accuracy')\n",
    "    val_accuracy = history.get('val_accuracy')\n",
    "    \n",
    "    if not all([loss, val_loss, accuracy, val_accuracy]):\n",
    "        print(\"Error: 학습 내역에 필요한 데이터가 부족합니다.\")\n",
    "        return\n",
    "    \n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    # 손실 그래프 시각화\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'bo-', label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 정확도 그래프 시각화\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, 'bo-', label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 주요 학습 요약 정보 출력\n",
    "    print(\"\\n=== 학습 요약 정보 ===\")\n",
    "    best_val_acc = max(val_accuracy)\n",
    "    best_epoch = val_accuracy.index(best_val_acc) + 1\n",
    "    min_val_loss = min(val_loss)\n",
    "    min_epoch = val_loss.index(min_val_loss) + 1\n",
    "    \n",
    "    print(f\"최고 검증 정확도: {best_val_acc:.4f} (Epoch {best_epoch})\")\n",
    "    print(f\"최소 검증 손실: {min_val_loss:.4f} (Epoch {min_epoch})\")\n",
    "    \n",
    "    # 하이퍼파라미터 정보 출력 (선택 사항)\n",
    "    if hyperparameters:\n",
    "        print(\"\\n=== 하이퍼파라미터 정보 ===\")\n",
    "        for key, value in hyperparameters.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    # 추가적인 그래프 저장 (선택 사항)\n",
    "    # 저장하려면 아래 코드를 활성화하세요.\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \"\"\"\n",
    "    plt.tight_layout()\n",
    "    save_loss_graph_path = os.path.join(model_dir, 'loss_history.png')\n",
    "    save_accuracy_graph_path = os.path.join(model_dir, 'accuracy_history.png')\n",
    "    plt.savefig(save_loss_graph_path)\n",
    "    plt.savefig(save_accuracy_graph_path)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n손실 그래프 저장: {save_loss_graph_path}\")\n",
    "    print(f\"정확도 그래프 저장: {save_accuracy_graph_path}\")\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353261b3-e71c-4128-87be-001c65f20df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def collect_and_evaluate_models(results_base_dir, test_data_dir, class_mode='binary', batch_size=32):\n",
    "    \"\"\"\n",
    "    모델 디렉터리의 각 모델을 테스트 데이터로 평가하고, 결과를 Excel 파일로 저장합니다.\n",
    "\n",
    "    :param results_base_dir: 모델 폴더들이 저장된 결과 디렉터리 경로\n",
    "    :param test_data_dir: 테스트 데이터가 저장된 디렉터리 경로\n",
    "    :param class_mode: 클래스 모드 ('binary' 또는 'categorical')\n",
    "    :param batch_size: 배치 크기\n",
    "    \"\"\"\n",
    "    model_performance_list = []\n",
    "\n",
    "    # 결과를 저장할 Excel 파일 경로\n",
    "    parent_dir = os.path.dirname(results_base_dir.rstrip('/\\\\'))\n",
    "    output_excel_path = os.path.join(parent_dir, 'model_performance.xlsx')\n",
    "\n",
    "    # 결과 디렉터리의 모든 하위 폴더 탐색\n",
    "    for model_name in os.listdir(results_base_dir):\n",
    "        model_dir = os.path.join(results_base_dir, model_name)\n",
    "        if not os.path.isdir(model_dir):\n",
    "            continue\n",
    "\n",
    "        model_path = os.path.join(model_dir, 'model.h5')\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"모델 파일을 찾을 수 없습니다: {model_dir}\")\n",
    "            continue\n",
    "\n",
    "        model_info = {'model_name': model_name}\n",
    "\n",
    "        # 모델 로드\n",
    "        try:\n",
    "            model = load_model(model_path)\n",
    "            print(f\"모델 로드 완료: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"모델 로드 중 오류 발생 ({model_name}): {e}\")\n",
    "            continue\n",
    "\n",
    "        # 모델의 입력 크기 가져오기\n",
    "        input_shape = model.input_shape[1:3]  # (height, width)\n",
    "        print(f\"모델의 입력 크기: {input_shape}\")\n",
    "\n",
    "        # 테스트 데이터 제너레이터 생성\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            test_data_dir,\n",
    "            target_size=input_shape,\n",
    "            batch_size=batch_size,\n",
    "            class_mode=class_mode,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # 모델 평가\n",
    "        try:\n",
    "            loss, accuracy = model.evaluate(test_generator, verbose=0)\n",
    "            print(f\"모델: {model_name}, 테스트 손실: {loss:.4f}, 테스트 정확도: {accuracy:.4f}\")\n",
    "            model_info['test_accuracy'] = accuracy\n",
    "            model_info['test_loss'] = loss\n",
    "        except Exception as e:\n",
    "            print(f\"모델 평가 중 오류 발생 ({model_name}): {e}\")\n",
    "            model_info['test_accuracy'] = None\n",
    "            model_info['test_loss'] = None\n",
    "\n",
    "        # 훈련 기록 로드\n",
    "        training_history_path = os.path.join(model_dir, 'training_history.json')\n",
    "        if os.path.exists(training_history_path):\n",
    "            try:\n",
    "                with open(training_history_path, 'r') as f:\n",
    "                    history = json.load(f)\n",
    "                # 마지막 에포크의 훈련 및 검증 정확도와 손실 추출\n",
    "                model_info['train_accuracy'] = history.get('accuracy', [None])[-1]\n",
    "                model_info['train_loss'] = history.get('loss', [None])[-1]\n",
    "                model_info['val_accuracy'] = history.get('val_accuracy', [None])[-1]\n",
    "                model_info['val_loss'] = history.get('val_loss', [None])[-1]\n",
    "            except Exception as e:\n",
    "                print(f\"{model_name}의 훈련 기록 로드 중 오류 발생: {e}\")\n",
    "                model_info['train_accuracy'] = None\n",
    "                model_info['train_loss'] = None\n",
    "                model_info['val_accuracy'] = None\n",
    "                model_info['val_loss'] = None\n",
    "        else:\n",
    "            print(f\"{model_name}의 훈련 기록을 찾을 수 없습니다.\")\n",
    "            model_info['train_accuracy'] = None\n",
    "            model_info['train_loss'] = None\n",
    "            model_info['val_accuracy'] = None\n",
    "            model_info['val_loss'] = None\n",
    "\n",
    "        # 모델 정보 리스트에 추가\n",
    "        model_performance_list.append(model_info)\n",
    "\n",
    "        # 메모리 정리\n",
    "        del model\n",
    "\n",
    "    # DataFrame 생성\n",
    "    df = pd.DataFrame(model_performance_list)\n",
    "\n",
    "    # DataFrame을 Excel 파일로 저장\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"모델 성능 데이터가 {output_excel_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ae630-33f7-4097-abf3-406bd1090387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEST",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
